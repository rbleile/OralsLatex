\subsection{Nuclear Data}

A large part of many Monte Carlo transport calculations is the process of looking up nuclear data information.
%
Both microscopic and macroscopic cross section information is needed in order to understand what reactions a particle undergoing a collision will do.
%
Depending on the problem and the choices made to solve it, time spent looking up nuclear data can often be between 10\% and 85\% of the over all runtime.
%
The problems that spend more time looking up cross section data are often using what is known as the continuous energy model where energy value are stored as a large sequence of points and exact values are found through interpolation.
%
The second method that is used which makes cross section lookups faster but less accurate is multi-group cross sections, where cross section data is stores in some number of bins and all energies that land in the bin are given the same value.
%
This can often reduce the search many orders of magnitude.
%

%
Research that deals with nuclear data lookups is often concerned with speeding up the search for a given cross section at a given energy.
%
This search problem is the main bottleneck in the cross section lookup algorithms.
%
Linear searches, binary searches, and Hash based searches are often employed for this.
%
In addition combining isotopes into a unionized grid is a common method for reducing the total number of searched required, though it greatly increases the memory needed to store the cross section data.
%

Each of the common competing continuous algorithms is well defined and compared by Wang et. al. and are described as follows ~\cite{wang2016competing}:
%
\subsubsection*{ Hashing: } Each material's whole energy range is divided up into N equal intervals, and for every individual isotope inside the material an extra table is established to store isotopic bounding indexes of each interval ~\cite{brown2014new}. The new search intervals are thus largely narrowed with respect to the original range and can be reached by a single float division. The hashing can be performed on a linear or logarithmic scale; the search inside each interval can be performed by a binary search or linear search. In the original paper ~\cite{brown2014new}, a logarithmic hashing was chosen with $ N \simeq 8000 $ as the best compramize between performance and memory usage. Another variant is to perform the hashing at the isotope level.
%
\subsubsection*{ Unionized grid: } A global unionized table gathers all possible energy points in the simulation and seconds table provides their corresponding indexes in each isotope energy grid ~\cite{leppanen2009two}. Every time an energy lookup is performed, only one search is required in the unionized gris and the isotope index are directly provided by the secondary index table. Timing resutls show that this method has a significant speedup over the conventional binary search but can require up to a 36$\times$ more memory space~\cite{a.l.lunda.r.siegel2015}.
%
\subsubsection*{ Fractional cascading: } This is a technique to speedup search operations for the same value in a series of related data sets ~\cite{a.l.lunda.r.siegel2015}. The basic idea is to build a unified grid for the first and second isotopes, then for seconds and third, etc. When using the mapping technique, once we find the energy index in the first energy grid all the following indexes can be read directly from the extra index teables without further computations. Compared to the global unionized methods, the fractional cascading technique greatly reduces memory usage.

%
We will discuss recent work done in the area of nuclear data lookups when we discuss many-core based Monte Carlo research as much of the results are targeted at NVIDA GPGPUs or the Intel XEON Phi many-core coprocessor. 
