%% Introduction Section %%
\section{ \textbf{Introduction}}

Today's Supercomputer landscape is in flux.
%
Supercomputer architectures are making more extreme changes then they have undergone in 20 years.
%
One big driving factor for this change are the concerns about energy usage as we scale to larger and larger machines.
%
A metric, FLOPS/Watt is often used to describe this relationship.
%
In order to maximize the FLOPS/Watt metric, architectures are shifting away from fast and complex multi-core CPUs and adding in much larger numbers of much slower simpler processors.
%
The amount of parallelism available on any given node in a supercomputer is growing but factors of hundreds or thousands because of this change.
%
This change brings new and interesting challenges that need to be overcome.
%

%
In addition to the increase in node level parallelism, it is unclear which architecture choice will prove to be a winning design.
%
Currently there are many different architectures to choose from when designing a supercomputer and there is no obvious choice to place one design above the others, or if any of these designs are going to end up above the others.
%
NVIDIA provides General Purpose Graphics Processing Units (GPGPUs) which are a highly parallel throughput optimized devices.
%
Intel provides their Many Integrated Core (MIC) co-processor which provides large vector lanes and many threads.
%
Other groups are turning to Field Programmable Gate Arrays (FPGAs) for a solution.
%
Across the Department of Energy (DOE) National Labs both the NVIDIA and Intel approaches are being pursued in their newest procurements ~\cite{coralWeb, trinityWeb}.
%

Application developers now face a complex and unclear path forward.
%
There is additional levels of complexity and potentially large application changes that will need to be made in order to effectively utilize this increase in parallelism.
%
In addition, an application programmer cannot simply begin a cycle of porting to a new hardware architecture.
%
Instead, applications need to address the issue of portability as well as performance or they run the risk of becoming outdated or unusable very quickly.
%
This problem is especially challenging when optimization choices for one architecture can contradict with optimization choices on another architecture.
%

%
There are a large number of physics and multi-physics applications that exist today that must figure out how to navigate this complex and challenging landscape.
%
Simple ports to new architectures are often not enough to guarantee performance, and will still require applications to be ported multiple times to multiple architectures.
%
This paper will explore these concerns and today's current efforts for portable performance solutions in the scope of one of these physics applications, Monte Carlo particle transport.
%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%